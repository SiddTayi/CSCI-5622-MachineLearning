---
title: "PART 2 -2"
author: "Siddharth Tayi"
date: "2023-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## PART 2

### Q1

### Coordinates: X1 = (-2, 4); Y1 = -1, X2 = (2, 2); Y2 = 1, X3 = (4, 2); Y3 = 1

$$
 \lambda_1 Y_1 + \lambda_2 Y_2 + \lambda_3 Y_3 = 0
$$

$$
 - \lambda_1 + \lambda_2 + \lambda_3 = 0
$$

$$
\lambda_3 =  \lambda_1 - \lambda_2 
$$

#### LAGRANGIAN CALCULATIONS

$$
L = \Sigma_{i = 1}^{3} \lambda_i * X_i * y_i - \frac{1}{2}[ \Sigma_{i = 1}^{3} \Sigma_{j = 1}^{3} \lambda_i \lambda_j X_i^T X_j  y_i y_j]
$$

$$
L = \lambda_1 + \lambda_2 + \lambda_3 + \frac{1}{2} \left[ \lambda_1^2 \sum (X_1 \cdot X_1) y_1^2 + \lambda_2^2 \sum (X_2 \cdot X_2) y_2^2 + \lambda_3^2 \sum (X_3 \cdot X_3) y_3^2 \right] + \lambda_1 \lambda_2 \sum (X_1 \cdot X_2) y_1 y_2 + \lambda_1 \lambda_3 \sum (X_1 \cdot X_3) y_1 y_3 + \lambda_2 \lambda_3 \sum (X_2 \cdot X_3) y_2 y_3
$$

$$
L = \lambda_1 + \lambda_2 + \lambda_3 + \frac{1}{2} \left[ \lambda_1^2 \sum (X_1 \cdot X_1) y_1^2 + \lambda_2^2 \sum (X_2 \cdot X_2) y_2^2 + \lambda_3^2 \sum (X_3 \cdot X_3) y_3^2 \right] + \lambda_1 \lambda_2 \sum (X_1 \cdot X_2) y_1 y_2 + \lambda_1 \lambda_3 \sum (X_1 \cdot X_3) y_1 y_3 + \lambda_2 \lambda_3 \sum (X_2 \cdot X_3) y_2 y_3
$$

$$
L = \lambda_1 + \lambda_2 + \lambda_3 + \frac{1}{2} \left[ \lambda_1^2 \left((-2)^2 + 4^2\right) (-1)^2 + \lambda_2^2 \left(2^2 + 2^2\right) (1)^2 + \lambda_3^2 \left(4^2 + 2^2\right) (1)^2 \right] + \lambda_1 \lambda_2 \left((-2)(2) + 4(2)\right) (-1)(1) + \lambda_1 \lambda_3 \left((-2)(4) + 4(2)\right) (-1)(1) + \lambda_2 \lambda_3 \left((2)(4) + 2(2)\right) (1)(1)
$$

$$
\begin{aligned}
L &= \lambda_1 + \lambda_2 + \lambda_3 \\
&+ \frac{1}{2} \left[ \lambda_1^2 \sum (X_1 \cdot X_1) y_1^2 + \lambda_2^2 \sum (X_2 \cdot X_2) y_2^2 + \lambda_3^2 \sum (X_3 \cdot X_3) y_3^2 \right] \\
&+ \lambda_1 \lambda_2 \sum (X_1 \cdot X_2) y_1 y_2 + \lambda_1 \lambda_3 \sum (X_1 \cdot X_3) y_1 y_3 + \lambda_2 \lambda_3 \sum (X_2 \cdot X_3) y_2 y_3
\end{aligned}
$$

$$
\begin{aligned}
L &= \lambda_1 + \lambda_2 + (\lambda_1 - \lambda_2) \\
&+ \frac{1}{2} \left[ \lambda_1^2 \sum (X_1 \cdot X_1) y_1^2 + \lambda_2^2 \sum (X_2 \cdot X_2) y_2^2 + (\lambda_1 - \lambda_2)^2 \sum (X_3 \cdot X_3) y_3^2 \right] \\
&+ \lambda_1 \lambda_2 \sum (X_1 \cdot X_2) y_1 y_2 + \lambda_1 (\lambda_1 - \lambda_2) \sum (X_1 \cdot X_3) y_1 y_3 + \lambda_2 (\lambda_1 - \lambda_2) \sum (X_2 \cdot X_3) y_2 y_3
\end{aligned}
$$

$$
\begin{aligned}L = &\, \lambda_1 + \lambda_2 + (\lambda_1 - \lambda_2) \\&+ \frac{1}{2} \left[ \lambda_1^2 \left((-2)^2 + 4^2\right) (-1)^2 + \lambda_2^2 \left(2^2 + 2^2\right) (1)^2 + (\lambda_1 - \lambda_2)^2 \left(4^2 + 2^2\right) (1)^2 \right] \\&+ \lambda_1 \lambda_2 \left[(-2)(2) + 4(2)\right] (-1)(1) + \lambda_1 (\lambda_1 - \lambda_2) \left[(-2)(4) + 4(2)\right] (-1)(1) \\&+ \lambda_2 (\lambda_1 - \lambda_2) \left[(2)(4) + 2(2)\right] (1)(1)\end{aligned}
$$

#### LAMBDA CALCULATIONS

$$
\lambda_3 = \lambda_1 - \lambda_2
$$

Substitute $\lambda_1 = -\frac{13}{28}$ and $\lambda_2 = \frac{1}{4}$ to calculate $\lambda_3$:

$$
\lambda_3 = -\frac{13}{28} - \frac{1}{4}
$$

### Weight Vector Calculation:

$$
\mathbf{w} = \lambda_1 \mathbf{X}_1 \cdot y_1 + \lambda_2 \mathbf{X}_2 \cdot y_2 + \lambda_3 \mathbf{X}_3 \cdot y_3
$$

Substitute the given values for $\lambda_i$, $\mathbf{X}_i$, and $y_i$ to calculate $\mathbf{w}$:

$$
\mathbf{w} = \left(-\frac{13}{28}\right) \cdot (-2, 4) \cdot (-1) + \left(\frac{1}{4}\right) \cdot (2, 2) \cdot 1 + \left(-\frac{4}{7}\right) \cdot (4, 2) \cdot 1
$$

$$
\mathbf{w} = \left(\frac{-5} {18}, \frac {-7} {36}\right)
$$

### Bias Term Calculation:

$$
y_i*\left(\mathbf{w} . X + b\right) - 1 = 0
$$

$$
\mathbf{w}^T . X + b = \left(\frac{-5}{18}, \frac{-7}{36}\right)^T . (4,2) + b
$$

$$
\frac{-5} {18} * 4 - \frac{-7}{36} * 2 + b = 0
$$

Simplify the equation, we get the value of b:

$$
b = \frac{35}{18}
$$

#### LINE EQUATION:

$$
\mathbf{W}^T. X + b = 0
$$

$$
\frac{-5}{18} . x_1 - \frac{-7}{36}.x_2 + \frac{35}{18} = 0
$$

Multiplying 36 on both the sides to cancel out the highest demonimator, we get:

$$
-10.x_1 - 7.x_2 + 35 = 0
$$

$$
= 10.x_1 + 7.x_2 - 35 = 0
$$
